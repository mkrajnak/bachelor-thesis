%=========================================================================
% (c) Michal Bidlo, Bohuslav KÅ™ena, 2008
\lstdefinelanguage{JavaScript}{
  keywords={typeof, new, true, false, catch, function, return, null, catch, switch, var, if, in, while, do, else, case, break, then, yield, const, ajax},
  basicstyle=\small,
  keywordstyle=\color{blue}\bfseries,
  ndkeywords={class, export, boolean, throw, implements, import, this},
  ndkeywordstyle=\color{darkgray}\bfseries,
  identifierstyle=\color{black},
  sensitive=false,
  comment=[l]{//},
  morecomment=[s]{/*}{*/},
  commentstyle=\color{purple}\ttfamily,
  stringstyle=\color{red}\ttfamily,
  morestring=[b]',
  morestring=[b]",
  frame=lines,
  numbers=left,
  numberstyle=\scriptsize,
  stepnumber=1,
  numbersep=8pt,
  showstringspaces=false,
  captionpos=b
}
\renewcommand{\lstlistingname}{Code sample}

\chapter{Introduction}
Virtualization has become very important and powerful tool used in various technology sectors. There are plenty of usecases including testing, learning and development. Availability and improvement of open source technologies is making this area even more competitive. As datacenters grow, there are several aspects that need to be considered when choosing the most suitable solution. Reasons and advantages why are businesses implementing virtualization solutions are growing\cite{virtualization}.

oVirt\cite{oVirt} provides complete stack of management functions allowing to control and monitor the whole realm of virtual datacenters. The presence of rich RESTful API, even allows us to build our own custom tools such as moVirt\cite{moVirt} and Ansible\cite{Ansible}. 

Nowadays, the internet is being overwhelmed by modern single page applications created by advanced Javascript frameworks. This paper is written around the project, which makes effort to build similar application for oVirt. Main focus will be placed on dialogs as they administrate big entities like virtual machines and templates. Each of those entities has huge number of fields that might be in relation with one another. The challenge is to make dialogs quick, responsive and force them to always provide valid data. Regarding data validity there are two specials cases. The first case represents fact, that many of fields can be prefigured from template. The other one is a case when we need to edit particular entity, so it is crucial to display data belonging to right entity, which needs to be edited. This points to the fact, that dependency handling and excellent state management based on decision made by user can influence the data in one or few other fields.

Redux is technology designed especially for state management of React\cite{React} applications. There are some recommendations not to use Redux\cite{Redux} to manage state of dialogs. Configuration dialogs of oVirt entities can contain up to 62 fields as shown in Appendix\ref{graph}. Verifying data throughout whole configuration process, field after field, via technologies like jQuery can lead to pretty complex code. This is the reason why thoroughly designed solution for state management is required. But in this case, it is so complex that it is necessary to know the values in various fields to make sure that user is selecting valid data. Template belonging only to certain cluster provides good example.

React allows us to create presentional part of application. Similiarly like Redux, React itself has mechanisms to manage state of components, but as our application expands, large number of components may cause problems which lead to birth of Redux. This project is developed with open source spirit and so is the project design delivered by Patternfly\cite{Patternfly} library of elements.

\chapter{oVirt}
oVirt is an open source virtualization management tool that provides centralized management of virtual datacenters, hosts, virtual machines, storage and networking infrastructure. oVirt platform consists of two main parts -- an oVirt engine and one or more oVirt nodes.


\section{oVirt engine}
oVirt engine is a Java application running as web service and represents the part where all management features resides. The service is communicating directly to VDSM(Virtual Desktop and Server Manager) allowing the users to deploy, start, stop, migrate and monitor virtual machines. It comes with advanced management features for virtual machine lifecycle, storage, networking and live migration. oVirt engine stores all the information about virtual machines, virtual networks and storages in PostgreSQL\cite{postgre} database. User interaction with engine can be achieved via built-in web application for users and administrators. External application like ManageIQ and moVirt manage data centers via provided REST API. Overview of oVirt architecture is described in Figure \ref{ovirt_architecture}.

\begin{figure}[h]
\center{\scalebox{0.8}{\includegraphics{architecture.eps}}}
\caption{oVirt architecture \cite{oVirtImg}}
\label{ovirt_architecture}
\end{figure}

\subsection{Administration portal}
Administration portal, also called Power user portal, is web based tool able to manage all available resources with user management. Administrator can grant and revoke user permissions and monitor data center via provided dashboards with graphs and statistics. 

\subsection{User Portal}\label{userportal}
More suited for end users is User Portal as it targets basic virtual machine management and access to virtual consoles secured by protocols SPICE\cite{SPICE} and VNC\cite{VNC}. User has only access to virtual machines and resources which was allocated to him by administrator.

\subsection{REST API}
External applications may influence datacenter management thanks to RESTful API. As a demonstration can be used Android application moVirt, which allows to manage and monitor datacenter from a smartphone. oVirt REST API supports both XML and JSON formats and it will be crucial part of development part described in this document.

\section{oVirt node}
Resources managed by oVirt engine belongs to one or more oVirt nodes, which are basically servers running RHEL, Fedora or Centos with enabled KVM\cite{kvm} hypervisor and VDSM daemon. VDSM deamon is an application written in Python that has control of all available resources including storage, networking and virtual machines. VDSM-Hooks\cite{hooks} allow to extend the VDSM functionality by a custom script which can be executed at certain lifecycle events of virtual machine. Management of virtual machines lifecycles and collection of statistics is possible via libvirt\cite{libvirt}. VDSM is also responsible for reporting all actions to engine.

\section{oVirt Entities}
Data managed by oVirt are structured to objects known as entities. Next few sections are focused on explanation of oVirt entities important for this thesis.

\textbf{Cluster} is logical group of hosts sharing the same storage domain and have the same CPU architecture or CPU family.

\textbf{Template} represents a copy of virtual machine. This functionality is very valuable especially in cases when you need to repeatedly create bigger amount of virtual machines with same of similar properties. Template also holds the information about hardware and software configurations of derived virtual machine. 

\noindent There are two possibilities how virtual machines can be created from template: 
\begin{enumerate}

\item \textbf{Thin provisioned} has an advantage that data storage of the virtual machine is just a thin copy so it saves disk resources. On the other hand there is also disadvantage in CPU capacity needed to manage disk diffs. Also once a new virtual machine is created by this method, template cannot be removed while the virtual machine exists in the environment. 

\item \textbf{Clone provisioned} is case where whole disks are copied from the template, so this method requires more disc capacity. A virtual machine created this way is independent on template therefore it can be removed at any time. 
\end{enumerate} 

\textbf{Virtual Machine} can be explained as actual computer system running in emulated environment and providing as much functionality as actual physical compute would provide.

\textbf{Host} is physical computer with installed hypervisor which allows to run multiple virtual machines on this host. oVirt usually has multiple host machines that are able to run as many virtual machines as resources allow.

\chapter{ManageIQ}\label{MIQ}
ManageIQ is open source cloud management tool able to manage environments of different sizes, as shown in Figure \ref{miq_architecture}. With support for platforms like oVirt, Open Stack, Kubernetes, Amazon Web Services, Google Cloud Platform, Microsoft Azure and many more allows user to control multiple technologies such as virtual machines, public clouds and containers from multiple vendors in single web application.
Application itself is written in Ruby and it can be deployed as virtual machine image and Docker container. 

From oVirt perspective ManageIQ can perform only basic tasks compared to tasks that are performable by oVirt web tools. Compared the all the functions implemented in oVirt Administration portal with \ref{graph}. Advantage is that user has data from every platform in one place with almost same amount of options as provided by each underlying tool. Disadvantage may be that user has to distinguish between products of various vendors which can become complicated when managing big number of entities. This project will focus on research of ManageIQ API from oVirt perspective and try to integrate it on similar layer as oVirt API.
Next sections are focused on ManageIQ architecture and are based on Gert Jansens article\cite{ManageIQarchitecture}.

\begin{figure}[h]
\center{\scalebox{0.75}{\includegraphics{manageIQ.eps}}}
\caption{ManageIQ architecture overview\cite{manageIQimg}}
\label{miq_architecture}
\end{figure}

\section{Discovery}
All platforms supported by ManageIQ are providing APIs. By integrating these API functions, ManageIQ can scan the environment and discover all virtual machines, hypervisors, containers, storages, networks and all the others resources. Discovered data of entities and its relations are stored in the Virtual Management Database(VMDB). 

After initial setup ManageIQ listens to events that are indicating changes and use them to refresh the VMDB. This way ManageIQ VMDB has always almost up to date data. It also features an option to make a full re-scan, which is also scheduled every 24-hours.
Data are presented to user via web interface. For oVirt instance displayed content are list of clusters, templates, virtual machines and all related attributes.

\section{Operational management}
Since API of various platforms allow us to control some of entities actions. Not all of the actions are covered, the goals is to be able to do main management features through ManageIQ. 
In case of oVirt entities user is able to create, edit virtual, clone and migrate virtual machines also perform basic tasks like power on, power off and reboot.

ManageIQ tracks the changes and can display reports about changes made to entities over time. It tracks attributes like discs, memory but in some cases it can track even software versions. Attribute changes can be compared to entities of same type or to entity itself from earlier time.

Resource management and monitoring is another advantage. ManageIQ provides various utilization charts of metrics like CPU, memory, disk with prediction when will these resources runs out of capacity.

ManageIQ can help in financial area. User can assign certain cost values to resources like Virtual machine memory and disk, so ManageIQ can provide report with costs of whole system or of certain group of users.

\section{Self-service}
This feature allows the administrator to create catalog of request that can be ordered by users. It saves a lot of time for an administrators and also for a user as the virtual machine or application are delivered to them faster. The administrator can create collection of service items represented as service bundle. Each item represent an entity which ManageIQ knows how to create for example a virtual machine or container. 

Some services require amount of input from user like memory and disk size in case of virtual machine. For this purpose the administrator can create a dialog via integrated dialog editor. Once the service bundle and dialogs are created, the service bundle needs to be associated with with an entry point which defines how this resource(virtual machine or container) will be provided. After completion of this process the service bundle can be inserted in the service catalog where it can be ordered by user. Once service is deployed user can start and stop virtual machine and has access to console. Services also have lifetime which can be set by administrator and service can be automatically terminated upon lifetime expiration. User is notified about expiration via email and might have an option to extend service.

\section{Compliance}
With ManageIQ administrators also have a tool for enforcing policies to discovered entities. When user deploy his own system via self-service administrator has at least some amount of control given back.

But ManageIQ give the administrators even bigger power with SmartState Analyses (SSA) technology. It allows to define rules for content of virtual machines, hypervisors and containers. SSA is able to discover configurations, logs and even package databases and store them directly to VMDB. SSA is implemented agent-less, it access the disks of systems via platform-specific APIs, usually snapshots or backup APIs. Disks cannot be safely mounted by Linux kernel, so ManageIQ implements its own Ruby-based read-only file system that access disks from user space. The agent-less implementation provide a big advantage that guests are not required to be cooperative so SSA works even on virtual machines which are currently shut down.

\chapter{Javascript Technologies}

\section{React}
React is an open source Javacript library dedicated to user interfaces. Application is divided to simpler components and each one of them is managing its own state. Components are built with emphasis on re-usability. Features like component nesting and conditional rendering\cite{conditional} allow us to make user interface modular and easier to maintain.

There are two types of React components\cite{React}:
\begin{enumerate}
\item \textbf{Stateless components} have no state management, they usually take props data and return what will actually be rendered on a page. The best way to define them might be via ES6 arrow functions\cite{arrowFunctions} but \texttt{React.Component} class with only \texttt{render()} function is also a possible solution.

\item \textbf{Stateful components} provide the full state management with an option to use component life-cycle methods. Any change of state will cause re-invoking of \texttt{render()} method and update of data presented on page. Every component of this kind should also define its initial state in a constructor that is compulsory.
Life-cycle of statefull components is controlled by life-cycle functions which are called on certain events (component update) in an specific order.
\end{enumerate}

Typical React work-flow is to create a stateful component containing multiple stateless components and pass them the data via \texttt{props}. A good practice is to define \texttt{PropTypes} to make sure that the correct data types are being passed to our component and even \texttt{DefaultProps} which will be used in case that value is not defined in \texttt{props}. 

\subsection{JSX} 
JSX\cite{JSX} is an Javascript extension recommended to be used with React. The implementation looks like actual HTML with the dynamic data from React variables. JSX has series of advantages:
\begin{itemize}
\item faster writing of HTML templates and better understanding of what content will actually be rendered
\item there is an optimization while code is being compiled to Javascript which gives it a better run-time performance
\item it is type-safe, so there is significant amount of error detected during compilation
\end{itemize}  

One of the limitations of JSX is a fact that some of the XML tag attributes are in namespace collision with Javascript. Therefore in actual JSX code attributes like \texttt{class} and \texttt{for} are being replaced with \texttt{className} and \texttt{htmlFor}, respectively. The modern web browsers are able to warn programmer when this kind of mistake is made with warning message in developer tools console. 

\section{Redux}
In the world of single page web applications requirements to manage state have become increasingly complicated. As application gains more complexity, more user interface elements and complicated API calls we can easily end up in a loop of events which source may be very hard to find. Of course there will be effort to make it right but it results to even more conditional event handling, thus created flaws are harder to reveal.

Redux is represented as a read-only tree of states called store. Every piece of data in store are describing the current state of application. The only way to change the state is to dispatch an action. Actions are predefined pure functions, therefore we can easily predict an actual change of state just from knowing dispatched action.

Actions are processed by pure functions called reducers. Reducer takes the current state and the action and returns a new state without mutation of the previous state. Because reducers are only functions, we are able to achieve specific state by dispatching right actions in right order. To conclude, Redux is based on three principles\cite{treePrinciples}:
\begin{enumerate}
\item Single store of truth -- the whole application state is stored within single tree
\item Store is read-only -- the only way to make a change is to dispatch an object describing the change (action)
\item Changes are made by pure functions -- reducers 
\end{enumerate}

\section{Redux-saga}
Redux-saga\cite{redux-saga} is a library providing functions for React/Redux applications which makes asynchronous actions like fetching data from external resources easier and better. Saga acts like separate thread which is responsible purely for side effects. Redux-Saga is a Redux middleware, so the thread can be started, paused and canceled via actions dispatched from application. It has also access to the data stored in the Redux store and can dispatch actions to influence it. The implementation is much easier thanks to the ES6 generator functions which make them easier to write and read because the code looks like synchronous Javascript.

\subsection{Saga middleware and sagas} \label{helpers}
The sagas are connected to the Redux store through the saga middleware. The middleware has to be created before the store and applied via \texttt{applymiddleware()} function. After application phase of the middleware and successful creation of the Redux store, the middleware can run sagas dynamically by invoking \texttt{middleware.run()} with saga as an argument. The middleware will go through the generator and execute all the yielded effects.

Sagas are functions which return a generator object. The saga-library provides also various effects which allows us to start other sagas. The first iteration of the middleware invoked the \texttt{next()} method. The yielded effects will be executed by the middleware according to effects API which specifies how will the middleware execute the sagas. While the effect is being executed, the generator is suspended. After receiving the result of the execution, the generator will call again the \texttt{next(result)} with the result as an argument. This process of the effects execution is repeated until the generator is terminated normally or by throwing some error. Saga can be also canceled either by effects or manually. Effect's executions which result in an error will cause invocation of \texttt{throw(error)} method of the generator. Also if the currently executed \texttt{yield} instruction is wrapped inside a \texttt{try/catch/finally} block and an error appears, the catch block will be executed followed by corresponding \texttt{finally} block.\cite{redux-saga-api}

\subsection{Effect creators}\label{effect_creators}
The following functions do not perform any executions and each one of them returns a plain Javascript object. The execution is performed by the middleware which examines the effect description and performs appropriate actions.

\texttt{take(pattern)} creates an effect which instructs the middleware to wait until the action with desired \texttt{pattern} is dispatched to the store. The pattern is interpreted be the following rules: 

\begin{itemize}
\item no arguments or pattern equals to a \texttt{'*'} means that all actions are suitable and every dispatched action is matched
\item in case that the pattern argument is a function, an incoming action has to be evaluated by the given function as true
\item when pattern is a string, it has to match \texttt{action.type}
\item in case that the pattern is an array, there are two possible cases:

\begin{itemize}
\item item incoming action has to match all the 			predicates if the pattern is the array of functions
\item it has to match all the strings in case of string array
\end{itemize}  
\end{itemize}  

The middleware also comes with a way to terminate all the sagas blocked on \texttt{take} effect which can be done by dispatching a special action \texttt{END}. Exceptions are sagas that have, in that particular moment, forked tasks. These sagas have to wait for children to end their tasks before terminating themselves.

\texttt{put(action)} creates an effect which instructs the middleware to dispatch a provided action to the store. The effect is non-blocking and the saga will not receive any thrown error feedback from a reducer. On the other hand \texttt{put.resolve(action)} is a variant of the effect which will wait until a promise returned from reducer is resolved.

\texttt{call(fn, ...args)} creates an effect that instructs the middleware to call the \texttt{fn} function with provided \texttt{args}. The passed function can be both generator function or normal function. The middleware will not only run the function but it also examines the result. The result can be a promise, an iterator function or a value. All three cases have different behavior:
\begin{itemize}
\item iterator object (generator) -- a parent generator is paused until the child generator finishes its task, the parent generator is resumed with the value returned by the child
\item promise -- a generator is  suspended until the promise is resolved or rejected
\item value -- the middleware returns value back to saga so it can continue its execution
\end{itemize}  

\subsection{Saga helper functions}
Saga helpers are functions built on top of the action creators described above, mainly \texttt{fork} and \texttt{take}.

\texttt{takeEvery} is a helper function that spawns a saga on each action dispatched to the store that matches certain pattern. It allows to write concurrent action that is handled as many times as action was dispatched, which means that new saga is started every time, even the previous sagas has not ended yet. There is also a race condition problem because there is no guarantee that saga will be terminated in the same order in which they have been started.

\texttt{takeLatest} also spawns a saga each time an action with a pattern is dispatched with one major difference. The previously started sagas which has not been terminated yet, are automatically canceled. So if saga is listening for an action with a certain pattern and user triggers the action multiple times, an old request is obsoleted by a new one. Of course this is only true in case that the old request has not been finished yet.

\texttt{throttle} listens to dispatched actions and spawn sagas when the action is received with one difference from the other two helper functions. After receiving the first action it will hold the execution of incoming action by certain time. Actions that have been received during given time are placed in a sliding buffer which means that only one most recent action will be kept. This is particularly useful in cases when we want to prevent our server from being flooded by requests.

\section{Redux-devtools}
As application state grows it may become pretty unclear what actions are being dispatched, when and how are they affecting the state. Using Javascript console for debugging might be confusing and even mislead us.

Redux-devtools allows programmers to go through every single action dispatched from the initial application state to the current state. Reducers are pure functions, so taking a series of actions applying them to a state will always yield the same result. The application basically becomes a movie which can be rewinded back and forth. Data in a store can be seen in every moment and after clicking on the dispatched actions programmer is provided with diff what exactly was changed. There is also an option to view application states as oriented graph, and move through its paths. As we inspect dispatched action, actual UI of application is changing too, because its state depend on the Redux store. Thanks to this we can easily see which actions triggers the changes in the UI or debug animations. In order for the Redux-devtool to properly work, a npm package needs to be added to project. The package comes with its own middleware applied to a store. 

The other part of Redux-devtools is composed from a web browser extension. The installed extension is accessible via button in the extension are of the browser. The extension icon automatically glows when the middleware is detected in loaded application. Extension menu allows user to display a new window with all the data in the store which are describing its current state of the application, with attached list of dispatched actions sorted chronologically from the start of the application.

\section{ImmutableJS}
ImmutableJS\cite{immutable} is library providing data structures like List, Stack, Map, OrderedMap, Set, OrderedSet and Record. Once any instances of these structures are created they will provide persistent and immutable data. The only way to make a change is to yield new updated copy. Usage of immutable data structures makes the application state predictable and assure us that changes are being made only in module we want to change them and avoid unnecessary bugs caused by mutation. In case of Redux changes of application state are handled by reducers.

\section{PatternFly}
Group of designers and open source enthusiasts have gathered together and created a set of practices for building user interfaces of enterprise web applications. Patternfly features color combinations, icons, dashboards, interactive widgets, pop-up windows, notifications, charts and many more components that can be included in modern web application. To get and initial set of icons and theming to our project we need to install a Patternfly module via npm\cite{npm} or yarn\cite{yarn}. Then just choose the right component for project via Patternfly website\cite{Patternfly} where is located all related HTML code. Some more complex components have its own module and they need to be installed separately. To achieve some functionality, user has to be able to look through actual code of the module. They also might require jQuery to run properly.

\chapter{Proposed solution}
Work done by this project becomes a part of an open source project oVirt Web UI. The goal of this project is to build a new basic User Portal \ref{userportal} which is now written as GWT\cite{gwt} application.
Current version of User Portal does not contain an option to edit or create virtual machines, these features belong only to Administration portal. One of the main goals of this project is to introduce them also to User Portal.
Dialogs in Administration portal need to update its state of fields after every change made by a user. The update itself can take up to few seconds and if the user works with the application on daily basis it can be pretty frustrating and lower the productivity. 
The current concept, in which are dialogs developed, also prone to bugs which are caused by a phenomenon called callback hell\cite{callback_hell}. The main reason why is this phenomenon hard to avoid is a big amount of dialog properties which are in very close relation to each other and may influence one another. From long time perspective, maintaining the code base can be very hard and may cause bugs by creating unwanted loops between callbacks. 

Important fact is to realize that purpose of the application is to provide user a tool that will be able to communicate with oVirt engine as well as the information about stored entities and a way to manage them. Application will not be able to work standalone and will depend on engine data. For development process we have been granted access to an oVirt instance used by oVirt developers in Red Hat.  

Our application will try to solve this problem by fetching as much data as possible right from the start with shallow updates scheduled for every minute. With all required data saved in Redux store, we can take advantage of proposed technologies and manage the state of dialogs.

\section{Comunication Layer}
This solution implements two possible backends oVirt REST API and ManageIQ REST API. Manage IQ integration of REST API has only been implemented as a proof of concept demonstrating the possibility of porting the oVirt Web UI to communicate with ManageIQ. Reasons behind this approach are few problems which disallowed us to implement the same level of functionality as we were able to implement with API provided by oVirt engine. To maintain the transparency between them, layers providing operations against API are developed as separate modules. Each module implements functions needed to fetch or alter the data.

Both APIs have similarities and operations against APIs are handled in both modules by \texttt{jQuery.ajax()}\cite{ajax} call for HTTP asynchronous request.
Request has to have proper header including \texttt{Authorization} and \texttt{Accept} fields. 

\bigskip
\begin{lstlisting}[language=javascript,xleftmargin=3.5ex,caption={Fetching data from ManageIQ with Basic Authentication}]
$.ajax(url, {
      'type': 'GET',
      'Accept': 'application/json',
      'Authorization': 'Basic YWRtaW46c21hcnR2bQ==',
    }).then(data => Promise.resolve(data))
\end{lstlisting}\label{base}
\bigskip
  
Recommended authentication method for both platforms is an authentication via token. There is also an option to use basic authentication method for development purposes, where password in only encoded by Base64 as shown in \ref{base}.
\texttt{Accept} field will use in our case \texttt{application/json} value because it is more suitable data format for Javacript than XML. Modules use several kinds of HTTP protocol methods: 
\begin{itemize}
\item \texttt{GET} method to obtain list of entities or one specific resource e.g. virtual machines, templates, clusters,
\item \texttt{POST} method is handling case when the user wants to create new entity or resource,
\item \texttt{PUT} to update resource data,
\item \texttt{DELETE} to delete data,
\item \texttt{OPTION} used by ManageIQ, explained in section \ref{miq},
\end{itemize}

Important part of the communication modules is to convert entities obtained from API to understandable form for front-end. Virtual machine is represented like an object with all properties required for the user. More entities are inserted in a list.

\section{oVirt API}
Every oVirt instance offers RESP API as another way to manage virtual data centers. An entry point to API is url \texttt{https://<hostaddress>/api} where we can access every available entity, url \texttt{https://<hostaddress>/api/vms} is where we can find list of all virtual machines.

Every entity has an unique ID, this ID can be used to access or edit one particular resource identified by the given ID. Internally we also have to pay attention to the type of entity because ID itself is not enough to address a resource. We have to classify the resource before we wake a request. Example for particular request would be the request to edit virtual machine, in which we have to send altered virtual machine data via HTTP \texttt{PUT} method to url \texttt{https://<hostaddress>/api/vms/<vmid>}. Additionally, to make sure that we have an access to full content of virtual machine properties, it is required to adjust the mentioned url by adding \texttt{?all\char`_content=true}.

Since there are policies and restrictions for certain data, oVirt engine may deny our request and answer it with an error message. We will be taking advantage of these messages, mainly because they are very descriptive so we immediately know what is wrong with our data. If a user typed for example a space inside virtual machine name, the error message would include description about restriction regarding virtual machine's names. 

\section{ManageIQ API}\label{miq}
As described in Chaper \ref{MIQ}, ManageIQ is quite different project which take an advantage of oVirt API in order to manage oVirt data centers. Because each one of the management tools has its own API, ManageIQ converting data to its own, unified representation. The resources provided by ManageIQ should contain all the data retrieved from underlying management tools.
Main entry point of API can be accessed via url \texttt{https://<hostaddress>/api}. It contains JSON with basic information and all accessible entities and url. 

\section{Manage IQ implementation}
This section is dedicated to the problems I encountered when I tried to implement ManageIQ support to the application. It also includes communication with ManageIQ developers and applying patches which were experimental and at that time, unapproved.

The same-origin policy\cite{policy} is an important security concept implemented in web browsers. Basically, it disallows the document or script to use resource that comes from another origin. Website has a different origin if it comes with different protocol, url or port. The intention of policy is to prevent a malicious website from reading the confidential information from other websites, it also prevents the application to read the data that might be offered by other website. A banking application with sensitive data is an good example demonstrating the purpose of this policy. Security is very important, but our application requires the data from ManageIQ API that are definitely not coming from the same origin as our application.

Thankfully HTTP protocol implements The Cross-Origin Resource Sharing(CORS)\cite{cors} mechanism to alleviate the same-origin policy, so Javascript is able to read REST API served from different origin. The CORS mechanism should be fully automatic, there is no need to alter the request headers. Any request from client which desires the cross-origin communication via \texttt{GET}, \texttt{POST}, \texttt{HEAD} method automatically includes on \texttt{Origin} field in header that describes the origin of a client. The server will evaluate the clients request and will either allow it or disallow it. If the first case is true, then the server will respond with requested resources and also include \texttt{Access-Control-Allow-Origin} field in response header. This does not mean that we can access the data, there is still a second part of evaluation which is made by the browser. The \texttt{Access-Control-Allow-Origin} has to be to present in the response header and must match with the request's \texttt{Origin} field. If those two do not match, browser will disallow our application to read the data. The \texttt{Access-Control-Allow-Origin} might contain * as a value, which means that everyone is able to access given resource but it is considered a bad practice.

There is one more complication to mechanism described above. If we make a request that is not considered simple, the web browser will make a preflight request. This request will basically ask if the application is allowed to access given resource, without actually performing it. Actual request is sent after the preflight has succeeded. Request is considered simple, if the client is making any of \texttt{GET}, \texttt{POST}, \texttt{HEAD} methods and content type is one of the following \texttt{application/x-www-form-urlencoded}, \texttt{multipart/form-data}, or \texttt{text/plain}. Also the fields in header are limited to \texttt{Accept}, \texttt{Accept-Language}, \texttt{Content-Language}. Because we need \texttt{Content-type} to be set to \texttt{application/json} and \texttt{Authorization} our requests are not considered simple and for every one of them requires a individual preflight request. The preflights are messages which use \texttt{OPTION} method, the server response contains list of allowed actions.

The routine described above should not cause a problem, but the server part of the routine was not implemented properly by ManageIQ. The response headers sent by the server did not contain \texttt{Access-Control-Allow-Origin} field, therefore any time a request was made by the client, the server did send an answer, however it was blocked by the web browser. This problem was reported as an issue\footnote{https://github.com/ManageIQ/manageiq/pull/14368} to ManageIQ Github page and the patch solving the issue was delivered. After patch application problem was solved only partially because preflight request were working only for the top level entities. So we were able to fetch the list of virtual machines but not the virtual machine information.

This problem can also be solved on client side but it is considered a bad practice that should be used only in development. The solution required to completely disable web browser security, thus no more preflight requests and no more same-origin policy enforcement. Since I believe that this problem will be solved by ManageIQ team in the future as a temporary solution I decided to disable it on Chromium browser by running it with\texttt{--disable-web-security --user-data-dir} parameters. Afterwards I was able to access all the entities.

\subsection{oVirt entities}
After solving initial problem everything was ready to fully integrate the application with ManageIQ. Initial research has shown that ManageIQ REST API provides only very small fraction of the information compared to oVirt REST API.
Basic task like creating a virtual machine requires at least the information about clusters, templates and optionally about virtual machines. Data of mentioned entities are accessible, however a list of operating systems is missing. 

When it comes to individual entities, they include the references to the original url from which it was given resource obtained. Most of the field contains url to oVirt API, some of the fields are even duplicated but they had different names. This leads us to the conclusion that these fields might have some internal purpose but for us are unusable. 

The only useful information belonging to cluster are name and id. Template consists only from id, name and cluster. It lacks important information about memory, cpu operating system and many more. In case of virtual machine id and name are consistent, however fields like template and memory differs from machine to machine. The most interesting was cluster field which holds only the url of original oVirt API resource. This pointed to the fact that it was not possible to determine which virtual machine belongs to the specific cluster. Also some of the very important resources like operating systems and important CPU and memory fields were completely missing.

There were also several unsuccessful attempts to create a virtual machine. From our point of view it looked like \texttt{POST} requests are handled be ManageIQ in the same way as \texttt{GET} requests. The received responses supported this	claim because the response code was always \texttt{400 OK} with list of resources instead of \texttt{401 created}. In the end from all the available actions we were able to perform only start and stop of the virtual machine.

Performance and speed is also not quite sufficient compared to oVirt API. The way virtual machines are arranged looks inappropriate. Lets say we want to download a list of all vms and all data for oVirt entities. Consider that ManageIQ also contains big number of virtual machine which belongs to different vendors. First \texttt{GET} to \texttt{/api/vms} will get us only the list of virtual machines with url and id of every single machine. So to get data of each virtual machine we need to make \texttt{GET} requests repeatedly for every machine with included preflight request. Only after downloading the virtual machine contents we can examine the vendor field and determine if machine belongs to oVirt. If not, we made useless request and we must drop the data and proceed to the next machine. Tests on our local ManageIQ instance with around 100 virtual machines shows that only fetching virtual machines lasts up to 10 seconds. Compared to oVirt API, Manage IQ is much slower considering that it contains less data than oVirt API.  

Result of this research shows that the oVirt segment of ManageIQ REST API is not yet ready for integration. The small part that was implemented and tested is not ready for user, because it misses key actions and data. We also have to mention the security problem with wrong header for OPTION method.

\begin{figure}[h]
\center{\scalebox{0.95}{\includegraphics{application_architecture.eps}}}
\caption{Application architecture}
\label{app_architecture}
\end{figure}

\section{Sagas}
The interconnection between proposed API modules, Redux store and React components is made by Redux-Saga middleware. Right after the start of the application, the created \texttt{sagaMiddleware} is applied to the store which means that from now on, it can properly run our sagas. The sagas are generator functions which allow us to make the code look more synchronous and prevent from creation of callback hell. The difference between generator functions and classic callbacks is that generators remain paused until the effect is resolved which is the main advantage for preventing the callback hell.

All created sagas are focused in a separate module \texttt{sagas.js}. Since we need to use more than one saga and running multiple sagas by the middleware might be quite unefficient, we will make one main \texttt{rootSaga}. The \texttt{rootSaga} is also a generator function which yields a list of saga helper functions \texttt{takeEvery} and \texttt{takeLatest}. Those helper functions map every created saga to a specific action, consequently these functions allow us to spawn one of the predefined sagas by dispatching an action. The behavior of spawned saga also depends on the kind of provided helper function as described in \ref{helpers}. Dispatching an action is not the only way to spawn a saga but it has certain advantages which are suitable for the Redux workflow. Generally, it is much easier for debugging through Redux-devtools because it shows order of actions which spawn generators one by one.

With all generators prepared and \texttt{rootSaga} running by the middleware, the application execution can continue. Assuming that we are using the development mode and we are logged in, the application will start with fetching the data from the oVirt engine. The process begins by calling \texttt{login} generator which will go step by step through series of generators fetching lists of all clusters, templates and virtual machines. Each one of mentioned generators are using local API instance that provides methods for fetching the data and their conversion to internal representation. Upon successful data retrieval and conversion, the data is dispatched to the store via specific actions. Those actions are processed by the corresponding reducers and saved to the Redux store. Part of this workflow is displayed on 
Figure \ref{app_architecture}.

Now, that the application has all the necessary data and we are able to see a list of virtual machines, it is ready for user interaction. The user can click on the \textit{Add virtual machine} button located above the list of virtual machine which triggers an action \texttt{SHOW\char`_BLANK\char`_DIALOG} caught by the \texttt{rootSaga} and spaws \texttt{showAddNewVm} saga. This saga will dispatch another set of actions required to open the dialog and several actions which will make sure that the dialog is initialized with empty values. There are also exceptions to this rule, for example some fields are set from the default template named \textit{Blank}. 

Furthermore, the Code Sample \ref{editVmSaga} explaines initiation of dialog that serves for editing virtual machines. Similarly like the Add virtual machine dialog, the dialog can be opened by the action from the user. In this case, the user has to click on the pencil button located either in the list of virtual machines or in the virtual machine detail window accessible after selecting any virtual machine from the list. Both of these options dispatch the same action which spawns the saga shown in the code sample. The saga is showing how we utilize generator functions within the project. In the beginning, the saga is provided with the action composed from a message type and a payload. The message type is in this case the string value \texttt{SHOW\char`_EDIT\char`_VM} which causes that the helper function defined in the \texttt{rootSaga} will spawn the \texttt{showEditVm} saga. 

The first effect of the saga will make sure that we have the most recent data of the virtual machine by refreshing the information about the virtual machine. The \texttt{yield} keyword provides an assurance that the generator will be paused until the effect is resolved, which means, that the most recent information about the virtual machine are stored in the Redux store. Since the Redux is the single store of truth, the next step of generator will lead to a selection of the virtual machine's data from Redux store. These data are picked by a custom function written in the dedicated \texttt{Selectors.js} module. The function will deliver the data from the store based on the provided virtual machine id.

The next step updates the dialog type which has to be done before opening the dialog. There are few things which might be rendered or initiated differently based on \texttt{dialogType} value from the Redux store.

The remaining sequence of effects is passing through the properties of virtual machine object. The properties are picked and dispatched to the part of the Redux store which is connected to individual fields of dialog. It is necessary to keep the right order of sequence because by changing some dialog fields we may change also several others. For example, changing the cluster will also cause the change of the template to the default value \texttt{Blank}. This is another case where we can show the asset provided by generator functions because the saga is paused until the effect is resolved. Just note that as described in \ref{effect_creators}, the \texttt{put} effect is non-blocking and it won't wait for effect result. But since the generator is only making the plain updates to the store, all that matters is the sequence in which updates are dispatched. After all the fields have been updated, the generator dispatches the last action which will open the dialog. The generator has ended and the dialog is ready to handle the user input.

\bigskip
\begin{lstlisting}[language=javascript,xleftmargin=3.5ex,caption={Saga responsible for initiating and showing the Edit VM dialog }]
function* showEditVm (action) {
yield fetchSingleVm(getSingleVm({vmId: action.payload.vm.get('id')}))
const vm = yield Selectors.getVmById(action.payload.vm.get('id'))
...
yield put(updateDialogType('edit'))
const cluster = Selectors.getClusterById(vm.get('cluster').get('id'))
yield put(updateCluster(cluster))
...
yield put(updateTemplate(template))
yield put(updateVmName(vm.get('name')))
yield put(updateVmDescription(vm.get('description')))
...
yield put(openVmDialog())
}
\end{lstlisting}\label{editVmSaga}
\bigskip

\section{React components}
The work described to this point of the thesis is from user perspective practically invisible. The part that must handle user interaction will be implemented in React with state management interconnected to Redux. 

Dialogs, which are we building have up to 62 fields representing a virtual machine and its properties. Since oVirt has been adding new features on relatively regular basis we need to provide easy way to include new fields when required. The key to keep dialog modular is to design sub-components which will allow us to easily add or remove fields. To achieve this goal we build standalone React components for every type of data we have to handle inside the dialog.

\subsection{Stateless components}
\texttt{LabeledTextField} is a component designed to obtain text input from a user. Input from user in this case may be represented either as a number or as text.

The variant dedicated to the numerical values can be initiated from a parent component by setting prop \texttt{type} to number. As shown in Figure~ \ref{labelledTextField}, the field has arrows which allows user to move numerical value by a certain step. The default step is 1 but I have included dedicated prop \texttt{step} that allow us to configure this value. The minimal value achievable by clicking on arrows can also be restricted by prop \texttt{min}. Those two props are especially useful in case of virtual machine's memory where we can make sure that the value will not be negative and we can set step for example to 256MB which is more convenient increment value for memory. 
The arrow buttons might also act as a hint pointing to a fact that the field requires a numerical value, especially when filling less known fields.

\begin{figure}[h]
\center{\includegraphics[scale=0.3]{LabelledTextField-number}}
\caption{LabeledTextField number variant}
\label{labelledTextField}
\end{figure} 

\texttt{LabeledSelect} component provides the user with a restricted list of values from which he selects only one value. In this component I have included two widgets with different features and look. The type of widget can be configured via \texttt{selectClass} prop. 

The first~--~classic widget provides the user with list of the options with default option pre-selected. This representation is suitable for cases when the list of options is short.

The other widget gives us different look and adds the type-ahead functionality (Figure \ref{labelledSelect}). User can simply start to type desired option and if it is available he can select it. The biggest advantage of the type-ahead functionality is maily in bigger lists of data where the values may be found much quicker compared to classic list. On the other hand there is a little disadvantage from the user perspective. Considering that user is able to type any value, I have implemented a verification process which checks if the value is really listed as an option. If not, user is notified via notification bubble with warning message specifying which field is wrong even before the data has been sent.

\begin{figure}[h]
\center{\includegraphics[scale=0.3]{LabeledSelect}}
\caption{LabeledSelect example with demonstration of type-ahead functionality}
\label{labelledSelect}
\end{figure} 

\texttt{Alert} can display red rectangle window with an error message inside. This component provides a transparent and simple demonstration of conditional rendering in React. The only prop passed from parent is the message itself. If the message contain an empty string, which is also initial state, \texttt{Alert} is rendered only as empty \texttt{<div$\backslash$>} without content or style. 
The error messages are in this case often result of failed REST API call. The errors are being detected by saga-middleware by examining the code from the server response. As soon as error is detected, saga will dispatch an action with an update which contains the error message from server. The message is processed by the corresponding reducer and store is updated. The update is broadcasted to React components which subscribed to updated part of store. In other words error message is displayed to a user immediately after the server response is received without any delays as shown in Figure \ref{alert}.

\begin{figure}[h]
\center{\includegraphics[scale=0.5]{alert}}
\caption{Error message from API displayed by error}
\label{alert}
\end{figure}

\texttt{LabeledSwitch} is an component dedicated to representation of boolean values. Like the previous components, it consists of two parts. A modern looking switch button (Figure \ref{switch}) which clearly describes two of possible states on or off and a label describing the feature which it configures in dialog. The component implementation is not adjusted to React yet, so we had to use the jQuery in the same manner like  we used in case of the \texttt{LabeledSelect} component. Similarly we had to use \texttt{componentDidMount} life-cycle method to initialize the component via custom method \texttt{bootstrapSwitch()}. Also the \texttt{onChange} callback within the React component cannot be used for triggering updates to the Redux store. The solution for correct detection and distribution of the changes made by user was the custom callback via jQuery triggered by \texttt{switchChange.bootstrapSwitch} event. But compared to the \texttt{LabeledText} the behavior was slightly different because we were not able to access proper state of the switch button via \texttt{ref} prop like we did in case of the other components. The value provided by the \texttt{ref} was \texttt{true} even though the switch was turned off. To solve this particular problem I had to examine the code of the widget itself and I discovered that the state is passed as an argument for every triggered \texttt{switchChange.bootstrapSwitch} event. This discovery allowed us to properly change the implemented callback which now can dispatch the state of the component right to the store.

\begin{figure}[h]
\center{\includegraphics[scale=0.3]{LabeledSwitch}}
\caption{LabaledSwitch for Smart card option}
\label{switch}
\end{figure}



\subsection{Stateful components}
\texttt{AddVmDialog} is a React component that implements our dialog representing a virtual machine and its configurable properties. The component can be used either to create or to edit a virtual machine. The dialog variant is determined by a value from the Redux store. The create virtual machine variant renders most of the fields empty, except special cases like cluster field where the pre-selected cluster is always the first cluster provided by the connected oVirt engine. Other fields like template, operating system, memory and cpu number are taken from the Blank template which is the default template for every cluster. The second variant is pre-filled with values from the virtual machine which is about to be edited as shown in the Figure \ref{editVMDialog}.

\begin{figure}[h]
\center{\scalebox{0.6}{\includegraphics{editVmDialog}}}
\caption{Dialog for editing virtual machines}
\label{editVMDialog}
\end{figure}

 
This dialog component is where we take an advantage of all the previously mentioned reusable sub-components. The difference between the \texttt{AddVmDialog} and previously described components is the fact that component is stateful whereas the others were stateless. This means that the component is created as a class which inherits from \texttt{React.Component}. Usage of a stateful variant is allowing us to use the life-cycle methods for proper sub-component initialization via jQuery. The component also needs to read the data from the sub-components which is achievable through \texttt{ref} attributes supported only by the stateful components.

The sub-components are placed in \texttt{AddVmDialog}'s \texttt{render()} method with all required props initiated for each one of them. Since components are reusable they have multiple options configurable via props. Therefore not all the props are required to be used in a parent component, only those which suit our current need. The props also come with the certain restrictions. Each of the sub-components defines its own \texttt{.propType} section with data type restriction and definition, which is describing whether the prop is or is not required. Optional props may acquire default values, e.g. \texttt{placeholder} prop is by default set to the same value as the \texttt{label} prop as long as it is not overwritten from parent.

The communication between the parent component is achieved through callbacks passed to sub-components via certain attributes (props). Those attributes are \texttt{ref} and \texttt{onChange}. The \texttt{ref} callback is a pure function which store the input in dialog field to a class property of the parent component. As an suitable example we can use cluster field where callback function is defined by following statement: \texttt{(input) => \{this.cluster = input\}}. Therefore the parent component is able to access the value of the cluster field by calling \texttt{this.cluster.value}. The \texttt{onChange} callback defines a function which will be called when change event occurs. In conclusion, these callbacks allow us to catch the change event in dialog field, read the data provided by \texttt{ref} and pass the obtained value to the Redux store.

The sub-component's props are not only the callbacks. The props are also used to carry values which are supposed to be rendered by a sub-component. This apply primarily to default values, placeholders and labels. The dialog is also using the props to configure the sub-components. 

The special case is \texttt{LabeledSelect} where the list of values rendered to user is passed via prop. To properly describe the problem I will be using the example which is implemented in the project. The dialog has a field which represents a list of templates. Each template depends on certain cluster (template Blank is an exception). In our dialog we know exactly which cluster is selected because we have this information stored in Redux store. Since we want to provide a user with valid data, it is necessary to render only the list of templates which applies to the selected cluster. This is achieved by a pure function which compares the ID of selected cluster with cluster ID stored in every loaded template. Afterwards, the filtered list of templates is sorted and sent to the \texttt{LabeledSelect} component.

The dialog always renders the data stored in Redux store in section \texttt{addVmDialog}. This is achieved by mapping the props of our dialog to a redux store state inside a \texttt{connect} method provided by react-redux library. 

\texttt{editTemplateDialog} is a second stateful React entity implemented in this project. The purpose of the dialog is to choose from the list of the templates provided by oVirt engine and to edit properties of single selected template. The implementation of this dialog has less fields but serves as a demonstration of transparency provided by designed React components. The added value is in another additional functionality brought to the oVirt-web-ui project. 

\section{Patternfly integration and design}
All React components and HTML related content are using styles provided by Patternfly. The library itself is accessible via dedicated npm module which needs to be included to gain access to styles and widgets. Not all widgets are included by default, the more complicated widgets that are implemented in Javascript and require jQuery have its own npm module which need to be included separately. In our project we have included few additional modules. A \texttt{bootstrap-combobox} module which implements the \texttt{LabeledSelect} type-ahead functionality and a \texttt{bootstrap-select} module used by simpler variant of the \texttt{LabeledSelect}. The last included module is \texttt{bootstrap-switch} and it provides the foundation for the switch button used in the \texttt{LabeledSwitch} component.

The combination of React and jQuery is the source of multiple implementation problems in front-end. As user is going through dialogs fields, they have to reflect choices he has already made. List of options in \texttt{LabeledSelect} component has to be properly re-rendered e.g. when needed. In order to re-render component which is using jQuery we have to use of the React life-cycle methods, to be specific \texttt{componentDidMount()} and \texttt{componentDidUpdate()} method. Every component using jQuery has a specific method which need to be called initially for component to properly render and work. These methods must be called from mentioned life-cycle. Thanks to this whenever user make a choice, Redux store will be update. If this change apply to part of store mapped to React component that is using jQuery, \texttt{componentDidUpdate()} is called and widget has a new list of values. 
Determine the method which initiate the jQuery work-flow in case of type-ahead variant of \texttt{LabeledSelect} wasn't simple. But we took advantage of a fact that Patternfly is an open source project, so we had to go through the code where we were able to find the right \texttt{combobox()} method, which initializes the component properly.

Styles for simple widgets like buttons or headings are added by providing HTML element with attribute \texttt{class} or \texttt{className} in case of JSX. List of classes with demonstrations can be found on Patternfly website\cite{Patternfly}. 

\section{Testing and verification}
The application was tested during whole development process. The main tool for testing reducers, actions and Redux store was the Redux-devtools extension and occasionally the Javascript console. The testing was done by manual execution of certain scenarios like opening and closing dialogs, switching values of certain fields. Verification process was manual but we have also used the Redux-devtools extension to verify the proper order of dispatched actions, payloads of actions and changes made by actions to the Redux store.

Another part of testing process was to verify data that should be created or updated by dialogs. In this case, verification process was in the beginning as simple as checking the return code from HTTP protocol. But as we were adding more fields after field to dialogs, we needed to check value by value. The main verification tools were the already implemented oVirt solutions. We started with the Administration Portal and moved  to the REST API, where we were able to simply open a web page containing data of virtual machine stored as XML and verify changed data by a simple refresh of the web page. Even in this part of testing we were able to use the Redux-devtools which can show us all the data stored in the Redux store. After every successful change made to the oVirt engine we use the generator to fetch updated data that we stored in Redux store. Therefore we were able to determine if the fresh data fetched from the oVirt engine include the change we to made.


\chapter{Possible alternative solution}

\chapter{Conclusion and future development}
The goal of this thesis was to design and implement a generic configuration interface for virtual machines and embed it to the oVirt Web Admin. The development focus is being shifted to oVirt Web UI project with probability that oVirt Web Admin will be completely obsoleted in the future. For this particular reason the proposed solution was embedded to the oVirt Web UI instead.

The solution has mapped all properties of virtual machine which is the biggest entity from the configuration standpoint. All dependencies and constraints were documented to the graph (Appendix \ref{graph}) which can possibly help with the project development in the future because the only alternative source of this data shown in graph is the source code of the oVirt engine.

The implemented back-end module is able to download list of virtual machines, templates and clusters. The module also includes methods which convert these entities to their individual internal representations. Furthermore, it contains methods for creating and editing virtual machines and also other methods which mostly secure the communication with the oVirt engine.

The thesis has also made a small research by experimentally implementing an alternative back-end module which uses the ManageIQ's REST API instead of the oVirt's REST API. The result of research has proven that the ManageIQ's REST API is not on the same level as the oVirt's REST API. Additionally, the research lead to a discovery of the bug caused by wrong CORS implementation. This discovery might help to improve the ManageIQ project in the future. 

I also experimented with the alternative solution for state management of dialogs secured only by React itself, without Redux. Even though the Redux is not recommended to be used for state management of the dialogs, our dialogs are unique and we have proven that it is possible and also very important for solving the callback hell which have caused many problems in the previous dialog implementation. The solution of the callback hell has been achieved through ES6 generator functions.

The final results include multiple dialogs. Probably the most important dialog is able to create a new virtual machine and warn about possible errors which appeared during this process. The second dialog allows the user to edit parameters of previously created virtual machines. The last of created dialogs offers a possibility to change parameters of templates managed by the oVirt engine.

The proposed React components also have some flaws. General flaw in components is caused by usage of jQuery which should be avoided in React. The Patterfly have already identified the problem and started a custom project which should provide components designed especially for React without jQuery as additional dependency\footnote{https://github.com/patternfly/patternfly-react}. Another minor issue might be a minor user experience flaw caused by the proposed combo box solution which requires addition click to cancel the previously selected value before selecting a new value from the list. The problem was also identified on Github page\footnote{https://github.com/danielfarrell/bootstrap-combobox/issues/149 } of component but the solution has not been included yet. The proposed solution only removes the X button which appears when value is selected in widget. The change can be done manually in source code of the component but it would lead to another problem with distribution of altered npm package.

The implementation side of this thesis has also tried to keep touch with an upstream project\footnote{https://github.com/oVirt/ovirt-web-ui}. The smaller patch with few dialog fields, React components and most of the back-end infrastructure has been included in adjusted form.


 
%=========================================================================
