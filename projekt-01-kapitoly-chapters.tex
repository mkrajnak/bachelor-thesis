%=========================================================================
% (c) Michal Bidlo, Bohuslav KÅ™ena, 2008

\chapter{Introduction}
Virtualization has become very important and powerful tool used in various technology sectors. There are plenty of usecases including testing, learning and development. Availability and improvement of open source technologies is making this area even more competitive. As datacenters grow, there are several aspects that need to be considered when choosing the most suitable solution. Reasons and advantages why are businesses implementing virtualization solutions are growing\cite{virtualization}.

oVirt\cite{oVirt} provides complete stack of management functions allowing to control and monitor the whole realm of virtual datacenters. The presence of rich Restful API, even allows us to build our own custom tools such as moVirt\cite{moVirt} and Ansible\cite{Ansible}. 

Nowadays, the internet is being overwhelmed by modern single page applications created by advanced Javascript frameworks. This paper is written around the project, which makes effort to build similar application for oVirt. Main focus will be placed on dialogs as they administrate big entities like virtual machines and templates. Each of those entities has huge number of fields that might be in relation with one another. The challenge is to make dialogs quick, responsive and force them to always provide valid data. Regarding data validity there are two specials cases. The first case represents fact, that many of fields can be prefigured from template. The other one is a case when we need to edit particular entity, so it is crucial to display data belonging to right entity, which needs to be edited. This points to the fact, that dependency handling and excellent state management based on decision made by user can influence the data in one or few other fields.

Redux is technology designed especially for state management of React\cite{React} applications. There are some recommendations not to use Redux\cite{Redux} to manage state of dialogs. Configuration dialogs of oVirt entities can contain up to 62 fields \ref{graph}. Verifying data throughout whole configuration process, field after field, via technologies like jQuery can lead to pretty complex code. This is the reason why thoroughly designed solution for state management is required. But in this case, it is so complex that it is necessary to know the values in various fields to make sure that user is selecting valid data. Template belonging only to certain cluster provides good example.

React allows us to create presentional part of application. Similiarly like Redux, React itself has mechanisms to manage state of components, but as our application expands, large number of components may cause problems which lead to birth of Redux. This project is developed with open source spirit and so is the project design delivered by Patternfly\cite{Patternfly} library of elements.

\chapter{oVirt}
oVirt is an open source virtualization management tool that provides centralized management of virtual datacenters, virtual hosts, virtual machines, storage and networking infrastructure. oVirt platform consists of two main parts - an oVirt engine and one or more oVirt nodes.


\section{oVirt engine}
oVirt engine is a Java application running as web service and represents the part where all management features resides. The service is communicating directly to VDSM(Virtual Desktop and Server Manager) allowing the users to deploy, start, stop, migrate and monitor virtual machines. It comes with advanced management features for virtual machine lifecycle, storage, networking and live migration. oVirt engine stores all the information about virtual machines, virtual networks and storages in PostgreSQL\cite{postgre} database. User interaction with engine can be achieved via built-in web application for users and administrators. External application like ManageIQ and moVirt manage data centers via provided REST API.

\begin{figure}[h]
\center{\scalebox{1}{\includegraphics{architecture.eps}}}
\caption{oVirt architecture \cite{oVirtImg}}
\label{vector}
\end{figure}

\subsection{Administration portal}
Administration portal is web based tool able to manage all available resources with user management. Administrator can grant and revoke user permissions and monitor data center via provided dashboards with graphs and statistics. 

\subsection{User Portal}\label{userportal}
More suited for end users is User Portal as it targets basic virtual machine management and access to virtual consoles secured by protocols SPICE\cite{SPICE} and VNC\cite{VNC}. User has only access to virtual machines and resources which was allocated to him by administrator.

\subsection{Rest API}
External applications may influence datacenter management thanks to RESTful API. As a demonstration can be used Android application moVirt, which allows to manage and monitor datacenter from a smartphone. oVirt Rest API supports both XML and JSON formats and it will be crucial part of development part described in this document.

\section{oVirt node}
Resources managed by oVirt engine belongs to one or more oVirt nodes, which are basically servers running RHEL, Fedora or Centos with enabled KVM\cite{kvm} hypervisor and VDSM daemon. VDSM deamon is an application written in Python that has control of all available resources including storage, networking and virtual machines. VDSM-Hooks\cite{hooks} allow to extend the VDSM functionality be custom script which can be executed at certain lifecycle events of virtual machine. Management of virtual machines lifecycles and collection of statistics is possible via libvirt\cite{libvirt}. VDSM is also responsible for reporting all actions to engine.

\section{oVirt Entities}
Data managed by oVirt are structured to objects known as entities. Next few sections are focused on explanation of oVirt entities important for this thesis.

\textbf{Cluster} is logical group of virtual machines sharing the same storage domain and have the same CPU architecture of CPU family.

\textbf{Template} represents a copy of virtual machine. This functionality is very valuable especially in cases when you need to repeatedly create bigger amount of virtual machines with same of similar properties. Template also holds the information about hardware and software configurations of derived virtual machine. 

\noindent There are two possibilities how virtual machines can be created from template: 
\begin{enumerate}

\item \textbf{Thin provisioned} is a way to create a virtual machine just with necessary information, all the other information are just reference to a template from which is the virtual machine derived. An advantage is that data storage of the virtual machine is just a thin copy so it saves disk resources. On the other hand there is also disadvantage in CPU capacity needed to manage disk diffs. Also once a new virtual machine is created by this method, template cannot be removed while the virtual machine exists in the environment. 

\item \textbf{Clone provisioned} is case where whole disks are copied from the template, therefore a virtual machine created this way is less dependent on template which can be removed at any time. This method requires more disc capacity.
\end{enumerate} 

\textbf{Virtual Machine} can be explained as actual computer system running in emulated environment and providing as much functionality as actual physical compute would provide.

\textbf{Host} is physical computer with installed hypervisor which allows to run multiple virtual machines on this host. oVirt usually has multiple host machines that are able to run as many virtual machines as resources allow.

\chapter{ManageIQ}\label{MIQ}
ManageIQ is open source cloud management tool able to manage environments of different sizes. With support for platforms like oVirt, Open Stack, Kubernetes, Amazon Web Services, Google Cloud Platform, Microsoft Azure and many more allows user to control multiple technologies such as virtual machines, public clouds and containers from multiple vendors in one modern web application.
Application itself is written in Ruby and it can be deployed as virtual machine image and Docker container. 

From oVirt perspective ManageIQ can perform most of the task that can be performed by oVirt web tools. Advantage is that user has data from every platform in one place with almost same amount of options as provided by each underlying tool. Disadvantage may be that user has to distinguish between products of various vendors which can become complicated when managing big number of entities. This project will focus on research of ManageIQ API from oVirt perspective and try to integrate it on similar layer as oVirt API.
Next sections are focused on ManageIQ architecture and are based on Gert Jansens article\cite{ManageIQarchitecture}.

\begin{figure}[h]
\center{\scalebox{0.75}{\includegraphics{manageIQ.eps}}}
\caption{ManageIQ architecture overview\cite{manageIQimg}}
\label{vector}
\end{figure}

\section{Discovery}
All platforms supported by ManageIQ are providing APIs. By integrating these API functions, ManageIQ can scan the environment and discover all virtual machines, hypervisors, containers, storages, networks and all the others resources. Discovered data of entities and its relations are stored in the Virtual Management Database(VMDB). 

After initial setup ManageIQ listens to events that are indicating changes and use them to refresh the VMDB. This way ManageIQ VMDB has always almost up to date data. It also features an option to make a full re-scan, which is also scheduled every 24-hours.
Data are presented to user via web interface. For oVirt instance displayed content are list of clusters, templates, virtual machines and all related attributes.

\section{Operational management}
Since API of various platforms allow us to control some of entities actions. Not all of the actions are covered, the goals is to be able to do main management features through ManageIQ. 
In case of oVirt entities user is able to create, edit virtual, clone and migrate virtual machines also perform basic tasks like power on, power off and reboot.

ManageIQ tracks the changes and can display reports about changes made to entities over time. It tracks attributes like discs, memory but in some cases it can track even software versions. Attribute changes can be compared to entities of same type or to entity itself from earlier time.

Resource management and monitoring is another advantage. ManageIQ provides various utilization charts of metrics like CPU, memory, disk with prediction when will these resources runs out of capacity.

ManageIQ can help in financial area. User can assign certain cost values to resources like Virtual machine memory and disk, so ManageIQ can provide report with costs of whole system or of certain group of users.

\section{Self-service}
This feature allows the administrator to create catalog of request that can be ordered by users. It saves a lot of time for an administrators and also for a user as the virtual machine or application are delivered to them faster. The administrator can create collection of service items represented as service bundle. Each item represent an entity which ManageIQ knows how to create for example a virtual machine or container. 

Some services require amount of input from user like memory and disk size in case of virtual machine. For this purpose the administrator can create a dialog via integrated dialog editor. Once the service bundle and dialogs are created, the service bundle needs to be associated with with an entry point which defines how this resource(virtual machine or container) will be provided. After completion of this process the service bundle can be inserted in the service catalog where it can be ordered by user. Once service is deployed user can start and stop virtual machine and has access to console. Services also have lifetime which can be set by administrator and service can be automatically terminated upon lifetime expiration. User is notified about expiration via email and might have an option to extend service.

\section{Compliance}
With ManageIQ administrators also have a tool for enforcing policies to discovered entities. When user deploy his own system via self-service administrator has at least some amount of control given back.

But ManageIQ give the administrators even bigger power with SmartState Analyses(SSA) technology. It allows to define rules for content of virtual machines, hypervisors and containers. SSA is able to discover configurations, logs and even package databases and store them directly to VMDB. SSA is implemented agent-less, it access the disks of systems via platform-specific APIs, usually snapshots or backup APIs. Disks cannot be safely mounted by Linux kernel, so ManageIQ implements its own Ruby-based read-only file system that access disks from user space. The agent-less implementation provide a big advantage that guests are not required to be cooperative so SSA works even on virtual machines which are currently shut down.

\chapter{Javascript Technologies}

\section{React}
React is an open source Javacript library dedicated to user interfaces. Application is divided to simpler components and each one of them is managing its own state. Components are built with emphasis on re-usability. Features like component nesting and conditional rendering\cite{conditional} allow us to make user interface modular and easier to maintain.

There are two types of React components\cite{React}:
\begin{enumerate}
\item \textbf{Stateless components} have no state management they usually take props data and return what will actually be rendered on page. The best way to define them might be via ES6 arrow functions\cite{arrowFunctions} but \texttt{React.Component} class with only \texttt{render()} function is solution as well.

\item \textbf{Stateful components} provide full state management with option to use component life-cycle methods. Any change of state will cause re-invoking of \texttt{render()} method and update of data presented on page. Every component of this kind should also define its initial state in constructor.
\end{enumerate}

Typical React work-flow is to create stateful component containing multiple stateless components and pass them data via \texttt{props}. Good practice is to define \texttt{PropTypes} to make sure that correct data types are being passed to our component and even \texttt{DefaultProps} which will be used is case that value is not defined in \texttt{props}. 

\subsection{JSX} 
JSX\cite{JSX} is an Javascript extension recommended to be used with React. It looks like actual HTML with dynamic data from React variables. JSX has series of advantages:
\begin{itemize}
\item faster writing of HTML templates and better understanding of what will actually be rendered
\item there is an optimization while code is being compiled to Javascript which gives better run-time performance
\item it is type-safe so there is significant amount of error detected during compilation
\end{itemize}  

One of the limitations of JSX is a fact that some of the XML tag attributes are in namespace collision with Javascript. Therefore in actual JSX code attributes like \texttt{class} and \texttt{for} are being replaced with \texttt{className} and \texttt{htmlFor} respectively. Fortunately modern have ability to warn programmers about this making mistake. 

\section{Redux}
In the world of single page web applications requirements to manage state have become increasingly complicated. As application gains more complexity, more ui elements and complicated api calls we can easily end up in a loop of events which source may be very hard to find. Of course there will be effort to make it right but it results to even more conditional event handling, thus creating flaws harder to reveal.

Redux is represented as read-only tree of states called store. Every piece of data in store are describing the current state of application. The only way to change the state is to dispatch an action. Actions are predefined pure functions, therefore we can easily predict actual change of state just from knowing dispatched action.

Actions are processed by pure functions called reducers. Reducer takes the current state and the action and returns a new state without mutation of previous state. Because reducers are only functions, we are able to achieve specific state by dispatching right actions in right order. To conclude, Redux is based on tree principles\cite{treePrinciples}:
\begin{enumerate}
\item Single store of truth -- whole application state is stored within single tree
\item Store is read-only -- the only way to make a change is to dispatch an object describing the change(action)
\item Changes are made by pure functions -- reducers 
\end{enumerate}

\section{Redux-devtools}
As application state grows it may become pretty unclear what actions are being dispatched, when and how are they affecting the state. Using Javascript console might be confusing and even mislead us.

Redux-devtools allows programmers to go through every single action dispatched from the initial application state to the current state. Reducers are pure functions, so taking a series of actions applying them to a state will always yield the same result. The application basically becomes a movie which can be rewinded back and forth. Data in a store can be seen in every moment and after clicking on the dispatched actions programmer is provided with diff what exactly was changed. There is also an option to view application states as oriented graph, and move through its paths. As we inspect dispatched action, actual UI of application is changing too, because its state depend on the Redux store. Thanks to this we can easily see which actions triggers the changes in UI or debug animations. It can be installed as an extension for web browser, there is also a package that needs to be added to project to be fully operational.
  
\section{Redux-saga}
Redux-saga\cite{redux-saga} is library which provides functions for React/Redux applications which making asynchronous actions like fetching data from external resources easier and better. Saga acts like separate thread which is responsible purely for side effects. Redux-Saga is a Redux middleware, so the thread can be started, paused and canceled via actions dispatched from application. It has also access to the data stored in the Redux store and can dispatch actions to influence it. It uses the ES6 generators functions which make them easier to write and read because the code looks like synchronous Javascript.

\section{ImmutableJS}
ImmutableJS\cite{immutable} is library providing data structures like List, Stack, Map, OrderedMap, Set, OrderedSet and Record. Once any instances of these structures are created they will provide persistent and immutable data. The only way to make a change is to yield new updated copy. Usage of immutable data structures makes the application state predictable and assure us that changes are being made only in module we want to change them and avoid unnecessary bugs caused by mutation. In case of Redux changes of application state are handled by reducers.

\section{PatternFly}
Group of designers and open source enthusiasts have gathered together and created a set of practices for building user interfaces of enterprise web applications. Patternfly features color combinations, icons, dashboards, interactive widgets, pop-up windows, notifications, charts and many more components that can be included in modern web application. To get and initial set of icons and theming to our project we need to install a Patternfly module via npm\cite{npm} or yarn\cite{yarn}. Then just choose the right component for project via Patternfly wesite\cite{Patternfly} where is located all related HTML code. Some more complex components have its own module and they need to be installed separately. To achieve some functionality, user has to be able to look through actual code of the module. They also might require jQuery to run properly.

\chapter{Proposed solution}
Work done by this project becomes a part of an open source project oVirt Web UI. The goal of this project is to build a new basic User Portal \ref{userportal} which is now written as GWT\cite{gwt} application with lack of speed and hardly maintainable code base. Dialogs in current solution need to update state of fields after every change made by a user. The update itself can take up to few seconds and if the user works with the application on daily basis it can be pretty frustrating and lower the productivity.

Important fact is to realize that purpose of the application is to provide user a tool that will be able to communicate with oVirt engine as well as the information about stored entities and a way to manage them. Application will not be able to work standalone and will depend on engine data. For development process we have been granted access to an oVirt instance used by oVirt developers in Red Hat.  

Our application will try to solve this problem by fetching as much data as possible right from the start with shallow updates scheduled for every minute. With all required data saved in Redux store, we can take advantage of proposed technologies and manage the state of dialogs.

\begin{figure}[h]
\center{\scalebox{1}{\includegraphics{application_architecture.eps}}}
\caption{Application architecture}
\label{vector}
\end{figure}

\section{Comunication Layer}
This solution implements two possible backends oVirt Rest API and ManageIQ Rest API. Manage IQ integration of Rest API is still in heavy development and there were few problems which disallowed us to implement the same level of functionality as we were able to implement with API provided by oVirt engine. To maintain the transparency between them, layers providing operations against API are developed as separate modules. Each module implements functions needed to fetch or alter the data.

Both APIs have similarities and Operations against APIs are handled in both modules by \texttt{jQuery.ajax()}\cite{ajax} call for HTTP asynchronous request.
Request has to have proper header including \texttt{Authorization} and \texttt{Accept} fields. 


\lstdefinelanguage{json}{
    basicstyle=\normalfont\ttfamily,
    numbers=left,
    numberstyle=\scriptsize,
    stepnumber=1,
    numbersep=8pt,
    showstringspaces=false,
    breaklines=true,
    frame=lines
}

\begin{figure}[h]
\begin{lstlisting}[language=json]
$.ajax(url, {
      'type': 'GET',
      'Accept': 'application/json',
      'Authorization': 'Basic YWRtaW46c21hcnR2bQ==',
    }).then(data => Promise.resolve(data))
\end{lstlisting}
\caption{Code sample for fetching data from ManageIQ with Basic Authentication}
\label{base}
\end{figure}

Recommended authentication method for both platforms is an authentication via token. There is also an option to use basic authentication method for development purposes, where password in only encoded using variant of Base64 as shown in \ref{base}.
\texttt{Accept} field will use in our case \texttt{application/json} value because it is more suitable data format for Javacript than XML. Modules use several kinds of HTTP protocol methods: 
\begin{itemize}
\item \texttt{GET} method to obtain list of entities or one specific resource e.g. virtual machines, templates, clusters,
\item \texttt{POST} method is handling case when the user wants to create new entity or resource,
\item \texttt{PUT} to update resource data,
\item \texttt{DELETE} to delete data,
\item \texttt{OPTION} used by ManageIQ, explained in section \ref{miq},
\end{itemize}

Important part of the communication modules is to convert entities obtained from API to understandable form for front-end. Virtual machine is represented like an object with all properties required for the user. More entities are inserted in a list.

\section{oVirt API}
Every oVirt instance offers RESP API as another way to manage virtual data centers. An entry point to API is url \texttt{https://<hostaddress>/api} where we can access every available entity. For example to access a list of virtual machines, we have to use \texttt{https://<hostaddress>/api/vms}.

Every entity has an unique ID, this ID can be used to access or edit one particular resource identified by the given ID. Internally we also have to pay attention to the type of entity because ID itself is not enough to address a resource. We have to classify the resource before we wake a request. Example for particular request would be the request to edit virtual machine, in which we have to send altered virtual machine data via \texttt{HTTP PUT} method to url \texttt{https://<hostaddress>/api/vms/<vmid>}.

Since there are policies and restrictions for certain data, oVirt engine may deny our request and answer it with an error message. We will be taking advantage of these messages, mainly because they are very descriptive so we immediately know what is wrong with our data. If a user typed for example a space inside virtual machine name, the error message would include description about restriction regarding virtual machine's names. 

\section{ManageIQ API}\label{miq}
ManageIQ is different project as described in chapter \ref{MIQ}. It is using oVirt API to manage oVirt data centers. Because each one of the management tools has its own API, ManageIQ converting data to its own, unified representation. The resources provided by ManageIQ by should contain all the data retrieved from underlying management tools.
Main entry point of API can be accessed via url \texttt{https://<hostaddress>/api}. It contains JSON with basic information and all accessible entities and url. 


\section{HTTP access control}
This section is dedicated to the problems I encountered when I tried to implement ManageIQ support to the application. It also includes communication with ManageIQ developers and applying patches which were experimental and at that time, unapproved.

The same-origin policy\cite{policy} is an important security concept implemented in web browsers. Basically, it disallows the document or script to use resource that comes from another origin. Website has a different origin if it comes with different protocol, url or port. The intention of policy is to prevent a malicious website from reading the confidential information from other websites, it also prevents the application to read the data that might be offered by other website. A banking application with sensitive data is an good example demonstrating the purpose of this policy. Security is very important, but our application requires the data from ManageIQ API that are definitely not coming from the same origin as our application.

Thankfully HTTP protocol implements The Cross-Origin Resource Sharing(CORS)\cite{cors} mechanism to alleviate the same-origin policy, so Javascript is able to read REST API served from different origin. The CORS mechanism should be fully automatic, there is no need to alter the request headers. Any request from client which desires the cross-origin communication via \texttt{GET}, \texttt{POST}, \texttt{HEAD} method automatically includes on \texttt{Origin} field in header that describes the origin of a client. The server will evaluate the clients request and will either allow it or disallow it. If the first case is true, then the server will respond with requested resources and also include \texttt{Access-Control-Allow-Origin} field in response header. This does not mean that we can access the data, there is still a second part of evaluation which is made by the browser. The \texttt{Access-Control-Allow-Origin} has to be to present in the response header and must match with the request's \texttt{Origin} field. If those two do not match, browser will disallow our application to read the data. The \texttt{Access-Control-Allow-Origin} might contain * as a value, which means that everyone is able to access given resource but it is considered a bad practice.

There is one more complication to mechanism described above. If we make a request that is not considered simple, the web browser will make a preflight request. This request will basically ask if the application is allowed to access given resource, without actually performing it. Actual request is sent after the preflight has succeeded. Request is considered simple, if the client is making any of \texttt{GET}, \texttt{POST}, \texttt{HEAD} methods and content type is one of the following \texttt{application/x-www-form-urlencoded}, \texttt{multipart/form-data}, or \texttt{text/plain}. Also the fields in header are limited to \texttt{Accept}, \texttt{Accept-Language}, \texttt{Content-Language}. Because we need \texttt{Content-type} to be set to \texttt{application/json} and \texttt{Authorization} our requests are not considered simple and for every one of them requires a individual preflight request. The preflights are messages which use \texttt{OPTION} method, the server response contains list of allowed actions.

The routine described above should not cause a problem, but the server part of the routine was not implemented properly by ManageIQ. The response headers sent by the server did not contain \texttt{Access-Control-Allow-Origin} field, therefore any time a request was made by the client, the server did send an answer, however it was blocked by the web browser. This problem was reported as an issue to ManageIQ Github page and the patch solving the issue was delivered. After patch application problem was solved only partially because preflight request were working only for the top level entities. So we were able to fetch the list of virtual machines but not the virtual machine information.

This problem can also be solved on client side but it is considered a bad practice that should be used only in development. The solution required to completely disable web browser security, thus no more preflight requests and no more same-origin policy enforcement. Since I believe that this problem will be solved by ManageIQ team in the future as a temporary solution I decided to disable it on Chromium browser by running it with\texttt{--disable-web-security --user-data-dir} parameters. Afterwards I was able to access all the entities.

\section{oVirt entities}
After solving initial problem everything was ready to fully integrate the application with ManageIQ. Initial research has shown that ManageIQ REST API provides only very small fraction of the information compared to oVirt REST API.
Basic task like creating a virtual machine requires at least the information about clusters, templates and optionally about virtual machines. Data of mentioned entities are accessible, however a list of operating systems is missing. 

When it comes to individual entities, they include the references to the original url from which it was given resource obtained. Most of the field contains url to oVirt API, some of the fields are even duplicated but they had different names. This leads us to the conclusion that these fields might have some internal purpose but for us are unusable. 

The only useful information belonging to cluster are name and id. Template consists only from id, name and cluster. It lacks important information about memory, cpu operating system and many more. In case of virtual machine id and name are consistent, however fields like template and memory differs from machine to machine. The most interesting was cluster field which holds only the url of original oVirt API resource. This pointed to the fact that it was not possible to determine which virtual machine belongs to the specific cluster. Not to mention completely missing resources like operating systems and important CPU and memory fields.

There were also several unsuccessful attempts to create a virtual machine. From our point of view it looked like \texttt{POST} requests are handled be ManageIQ in the same way as \texttt{GET} requests. The received responses supported this	claim because the response code was always 400 OK with list of resources instead of 401 created. In the end from all the available actions we were able to perform only start and stop of the virtual machine.

Performance and speed is also not quite sufficient compared to oVirt API. The way virtual machines are arranged looks inappropriate. Lets say we want to download a list of all vms and all data for oVirt entities. Consider that ManageIQ also contains big number of virtual machine which belongs to different vendors. First \texttt{GET} to \texttt{/api/vms} will get us only the list of virtual machines with url and id of every single machine. So to get data of each virtual machine we need to make \texttt{GET} requests repeatedly for every machine with included preflight request. Only after downloading the virtual machine contents we can examine the vendor field and determine if machine belongs to oVirt. If not, we made useless request and we must drop the data and proceed to the next machine. Tests on our local ManageIQ instance with around 100 virtual machines shows that only fetching virtual machines lasts up to 10 seconds. Compared to oVirt API, Manage IQ is much slower considering that it contains less data than oVirt API.  

Result of this research shows that the oVirt segment of ManageIQ REST API is not yet ready for integration. The small part that was implemented and tested is not ready for user, because it misses key actions and data. We also have to mention the security problem with wrong header for OPTION method.

\section{Saga middleware operations}

\section{React components}
The work described to this point of the thesis is practically invisible. The part that must handle user interaction will be implemented in React with state management dedicated to Redux. 

Dialogs, which are we building have up to 62 fields and there are always new features which can be added to oVirt and need to be configurable. The key to keep dialog modular is to design sub-components which allow us to easily add or remove fields. To achieve this goal we build standalone React components for every type of data we have to handle in dialog.

\textbf{LabeledTextField} is a component designed to obtain text input from a user. Input from user in this case may be represented either as a number or as text. Component is configurable from parent component via \texttt{props} with restricted \texttt{propTypes}.
In case of number value a programmer can set \texttt{min} value \texttt{prop}, so for example in case of virtual machine's memory we can make sure that the value is not negative. Another useful \texttt{prop} in case of numerical value is \texttt{step} which allows user to increase or decrease the value inside field by certain amount via small arrow buttons. The amount is decided by programmer but all \texttt{props} have default value which is used in case that programmer does not set given props in parent component. The arrow buttons are the only difference between text and numerical output and also provide good guidance for the user what value is expected.
Fields with text output are more common which is the reason why is text default  input type. 

\textbf{LabeledSelect} component prodes user with list of values which can be selected. It features \texttt{selectClass prop} which determies the type of widget will be used. 
The first -- classic option provides user with list of the options with default option pre-selected. This representation is suitable for cases when the list of options is short.
The other option is similar combo box but with type-aheads. User can simply start to type desired option and if it is available he can select it. Advantage is mainly when selecting operating system for a virtual machine because list is typically longer than height of screen. Because user is able to type any value there is always a verification process which checks if a value is really listed as an option. If not, user is notified via notification bubble with warning message specifying which input is wrong even before the date are sent.




\section{Patternfly integration}

\section{Future development}

\chapter{Conclusion}

%=========================================================================
